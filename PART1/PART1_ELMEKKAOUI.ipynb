{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROJET DATA PART1 ALS ___ EL MEKKAOUI FAYSSAL __ ELAMMARI SOUHAIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importer les packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.evaluation.RegressionEvaluator\r\n",
       "import org.apache.spark.ml.recommendation.ALS\r\n",
       "import org.apache.spark.sql.types.IntegerType\r\n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "import org.apache.spark.ml.recommendation.ALS\n",
    "import org.apache.spark.sql.types.IntegerType\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation de la Class Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class Rating\r\n",
       "parseRating: (str: String)Rating\r\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class Rating(userId: Int, movieId: Int, rating: Float, timestamp: Long)\n",
    "def parseRating(str: String): Rating = {\n",
    "  val fields = str.split(\"::\")\n",
    "  assert(fields.size == 4)\n",
    "  Rating(fields(0).toInt, fields(1).toInt, fields(2).toFloat, fields(3).toLong)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture du fichier csv et transformation des types string en Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [userId: string, movieId: string ... 2 more fields]\r\n",
       "ratin: org.apache.spark.sql.DataFrame = [userId: int, movieId: string ... 2 more fields]\r\n",
       "rating: org.apache.spark.sql.DataFrame = [userId: int, movieId: int ... 2 more fields]\r\n",
       "ratings: org.apache.spark.sql.DataFrame = [userId: int, movieId: int ... 2 more fields]\r\n"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "val df = spark.read.option(\"header\",true)\n",
    "    .csv(\"C:/Users/user/Desktop/ratings.csv\")\n",
    "  \n",
    "val ratin = df.withColumn(\"userId\",col(\"userId\").cast(IntegerType))\n",
    "val rating = ratin.withColumn(\"movieId\",col(\"movieId\").cast(IntegerType))\n",
    "val ratings = rating.withColumn(\"rating\",col(\"rating\").cast(IntegerType))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userId: int, movieId: int ... 2 more fields]\r\n",
       "test: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userId: int, movieId: int ... 2 more fields]\r\n"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(training, test) = ratings.randomSplit(Array(0.8, 0.2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction du model de recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "als: org.apache.spark.ml.recommendation.ALS = als_cc361a249ee6\r\n"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val als = new ALS()\n",
    "  .setMaxIter(5)\n",
    "  .setRegParam(0.01)\n",
    "  .setImplicitPrefs(true)\n",
    "  .setUserCol(\"userId\")\n",
    "  .setItemCol(\"movieId\")\n",
    "  .setRatingCol(\"rating\")\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model: org.apache.spark.ml.recommendation.ALSModel = ALSModel: uid=als_cc361a249ee6, rank=10\r\n"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 3.1103882701306165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predictions: org.apache.spark.sql.DataFrame = [userId: int, movieId: int ... 3 more fields]\r\n",
       "evaluator: org.apache.spark.ml.evaluation.RegressionEvaluator = RegressionEvaluator: uid=regEval_6cef6d5a1100, metricName=rmse, throughOrigin=false\r\n",
       "rmse: Double = 3.1103882701306165\r\n",
       "userRecs: org.apache.spark.sql.DataFrame = [userId: int, recommendations: array<struct<movieId:int,rating:float>>]\r\n",
       "movieRecs: org.apache.spark.sql.DataFrame = [movieId: int, recommendations: array<struct<userId:int,rating:float>>]\r\n"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.setColdStartStrategy(\"drop\")\n",
    "val predictions = model.transform(test)\n",
    "\n",
    "val evaluator = new RegressionEvaluator()\n",
    "  .setMetricName(\"rmse\")\n",
    "  .setLabelCol(\"rating\")\n",
    "  .setPredictionCol(\"prediction\")\n",
    "val rmse = evaluator.evaluate(predictions)\n",
    "println(s\"Root-mean-square error = $rmse\")\n",
    "\n",
    "// Generate top 10 movie recommendations for each user\n",
    "val userRecs = model.recommendForAllUsers(10)\n",
    "// Generate top 10 user recommendations for each movie\n",
    "val movieRecs = model.recommendForAllItems(10)\n",
    "\n",
    "userRecs.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UserRecs : reccommandation des films pour chaque utilisateur\n",
    "### movieRecs : recommandation des Users pour chaque film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|   471|[[2571, 0.5197625...|\n",
      "|   463|[[318, 0.40459764...|\n",
      "|   496|[[2571, 0.3016072...|\n",
      "|   148|[[68954, 0.559856...|\n",
      "|   540|[[2571, 0.5525483...|\n",
      "|   392|[[2571, 0.3379473...|\n",
      "|   243|[[380, 0.77037174...|\n",
      "|    31|[[356, 0.6742091]...|\n",
      "|   516|[[2571, 0.3240862...|\n",
      "|   580|[[2571, 1.314706]...|\n",
      "+------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------+--------------------+\n",
      "|movieId|     recommendations|\n",
      "+-------+--------------------+\n",
      "|   1580|[[45, 1.2400022],...|\n",
      "|   4900|[[414, 0.62973076...|\n",
      "|   6620|[[474, 1.0908772]...|\n",
      "|   7340|[[414, 0.697927],...|\n",
      "|  32460|[[105, 0.6989926]...|\n",
      "|  54190|[[89, 0.81857014]...|\n",
      "|    471|[[474, 1.1514992]...|\n",
      "|   1591|[[274, 0.97374576...|\n",
      "| 140541|[[89, 0.42497468]...|\n",
      "|   1342|[[387, 0.64905417...|\n",
      "+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userRecs.show(10)\n",
    "movieRecs.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
