{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART2 DATA ELMEKKAOUI _ ELAMMARI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: import the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@3baa5ff0\r\n",
       "import sqlContext.implicits._\r\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n",
    "import sqlContext.implicits._\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 : read the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file: org.apache.spark.rdd.RDD[String] = C:/Users/user/Desktop/data.txt MapPartitionsRDD[47] at textFile at <console>:35\r\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val file = sc.textFile(\"C:/Users/user/Desktop/data.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 : get number of partitions after .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res23: Long = 25000000\r\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 : view top 2 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21,B+,Gurgaon,F,1\n",
      "38,B+,Gurgaon,M,2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "L: Array[String] = Array(21,B+,Gurgaon,F,1, 38,B+,Gurgaon,M,2, 20,A-,Bengaluru,F,3, 20,A-,Hyderabad,F,4, 30,A+,Bengaluru,F,5)\r\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var L = file.take(5)\n",
    "println(L(0))\n",
    "println(L(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5 Q6 Q7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "persons: org.apache.spark.sql.DataFrame = [age: int, blood: string ... 3 more fields]\r\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val persons = file.map(_.split(\",\")).map{case Array(a,b,c,d,e) => (a.toInt,b,c,d,e.toInt)}.toDF(\"age\",\"blood\",\"city\",\"sexe\",\"id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8 +Q9 : show top 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---------+----+---+\n",
      "|age|blood|     city|sexe| id|\n",
      "+---+-----+---------+----+---+\n",
      "| 21|   B+|  Gurgaon|   F|  1|\n",
      "| 38|   B+|  Gurgaon|   M|  2|\n",
      "| 20|   A-|Bengaluru|   F|  3|\n",
      "| 20|   A-|Hyderabad|   F|  4|\n",
      "| 30|   A+|Bengaluru|   F|  5|\n",
      "+---+-----+---------+----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q11: get the value count using the sql query and view results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res25: Long = 25000000\r\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persons.select(\"age\").count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10: value counts of gender using “groupby”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|sexe|   count|\n",
      "+----+--------+\n",
      "|   F|16978072|\n",
      "|   M| 8021928|\n",
      "+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons.groupBy(\"sexe\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|   avg(age)|\n",
      "+-----------+\n",
      "|24.99966288|\n",
      "+-----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "person_avg: org.apache.spark.sql.DataFrame = [avg(age): double]\r\n"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val person_avg = persons.agg(avg(\"age\"))\n",
    "person_avg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q12: perform another SQL query to calculate the average age in a city and view the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|     city|          avg(age)|\n",
      "+---------+------------------+\n",
      "|  Chennai|25.000232012755188|\n",
      "|  Gurgaon|24.998841877614932|\n",
      "|     Pune|25.000009997274816|\n",
      "|Bengaluru|25.000442672151312|\n",
      "|Hyderabad|24.998557155691067|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "persons.groupBy(\"city\").agg(avg(\"age\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
